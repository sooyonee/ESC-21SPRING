## 21-1 ESC Final Project Guideline ğŸ—‚

### 1. Goal

- Difference between Frequentist point of view and Bayesian point of view
- Interpreting model in Bayesian perspective
- ì˜ˆì¸¡ ë³´ë‹¤ëŠ”, "í•´ì„"ì´ ì£¼ ëª©ì 



### 2. Workflow

**1ì£¼ì°¨ : Choose dataset / Prep-processing / Feature Extraction / EDA+Visualization**

ë°ì´í„° ë¶„ì„ ì´ì „ì— ë°ì´í„°ì˜ ê°œí˜•ì„ íŒŒì•…í•˜ê³  ì§ê´€ì„ ì–»ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤. í•´ì•¼í•  ì¼ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 

- **Choosing Dataset** : ì•„ë˜ ì†Œê°œë  ë°ì´í„°ì…‹ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤. ê¼­ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ì„ íƒí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ì œì‹œëœ ë°ì´í„°ì…‹ì´ ì•„ë‹Œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ì œê³µëœ ë°ì´í„°ì˜ ì˜ˆì¸¡ ë³€ìˆ˜ë¥¼ ë‹¤ë¥¸ ë³€ìˆ˜ë¡œ ì •ì˜í•˜ê±°ë‚˜, ì¶”ê°€ë¡œ ë°ì´í„°ë¥¼ ë¶™ì—¬ì„œ ë¶„ì„ì„ í•˜ëŠ” ê²ƒ ëª¨ë‘ ì¢‹ìŠµë‹ˆë‹¤.
  **â° 5ì›” 21ì¼ ê¸ˆìš”ì¼ ì˜¤í›„ 7ì‹œê¹Œì§€ í•™ìˆ ë¶€ì¥ì—ê²Œ ê°œì¸í†¡ìœ¼ë¡œ ì–´ë–¤ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í• ê±´ì§€ 1, 2ì§€ë§ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì„ ì°©ìˆœì´ê³ , ì´ëŠ” ê°€ëŠ¥í•˜ë©´ ê° ë°ì´í„°ë‹¹ ë‘ ì¡°ë¥¼ ë„˜ì§€ ì•Šê²Œ ì¡°ì •í•˜ê³ ì í•¨ì…ë‹ˆë‹¤. **

- **Pre-Processing** : ë°ì´í„°ì˜ íŠ¹ì„±ìƒ ì „ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‹œê³„ì—´ ë³€ìˆ˜ê°€ í¬í•¨ë˜ì–´ ìˆê±°ë‚˜, ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ numericí•˜ê²Œ ì½”ë”©í•˜ê¸°, NA imputation ë“±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ ë°ì´í„°ì˜ ë¶„í¬ì™€ ë‹¨ìœ„ ì°¨ì´ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì ì ˆí•˜ê²Œ ë³€í™˜ ë° ìŠ¤ì¼€ì¼ë§ì„ í•´ì•¼ í•©ë‹ˆë‹¤. ëª¨ë“  ë³€ìˆ˜ì˜ ë¶„í¬ê°€ ê°™ì„ í•„ìš”ëŠ” ì—†ì§€ë§Œ, ê°™ì€ ë‹¨ìœ„ì— ìˆëŠ” ê²ƒì´ ë°”ëŒì§í•©ë‹ˆë‹¤. 

- **Feature Extraction** : ì—¬ëŸ¬ ë³€ìˆ˜ë¥¼ í•©ì³ì„œ ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ë§Œë“¤ê±°ë‚˜, ì™¸ë¶€ ë°ì´í„°ì—ì„œ ì–»ì€ ë³€ìˆ˜ë¡œ ìƒˆë¡œìš´ featureë¥¼ ì¶”ê°€í•˜ê±°ë‚˜, correlation analysis ë“±ì„ í†µí•´ multicolinearityê°€ ìˆëŠ” ë³€ìˆ˜ë¥¼ ë¶„ì„ì—ì„œ ì œì™¸í•˜ëŠ” ë“±ì˜ ì‘ì—…ì…ë‹ˆë‹¤. ë³€ìˆ˜ë“¤ ë¼ë¦¬ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ê²½ìš° ë‹¨ìˆœíˆ ì‚­ì œë¥¼ í•  ìˆ˜ë„ ìˆê³ , ì ì¬ë³€ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ë³€ìˆ˜ë¥¼ ë§Œë“¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

  ğŸ“ **ì£¼ì˜: ë³€ìˆ˜ ì„ íƒ ë‹¨ê³„ê°€ ì•„ë‹™ë‹ˆë‹¤! ë³€ìˆ˜ ì„ íƒì€ ëª¨ë¸ì„ ì„¸ìš°ê³  ë‚œ í›„ì— ì§„í–‰í•©ë‹ˆë‹¤!**

- **EDA+Visualization** : EDAëŠ” Pre-Processingê³¼ Feature Extractionê³¼ ë³‘í–‰í•˜ì—¬ ë°ì´í„°ì— ëŒ€í•´ ì•Œì•„ê°€ëŠ” 1ì£¼ì°¨ ì „ë°˜ì— ê±¸ì³ ì‹œí–‰í•©ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ ê¸°ìˆ í†µê³„ëŸ‰ì´ë‚˜ skewnessë¥¼ ë³´ê±°ë‚˜, normal assumptionì„ ì ìš©í•  ìˆ˜ ìˆëŠ”ì§€, ë³€ìˆ˜ ì¬ì •ì˜ê°€ í•„ìš”í•˜ì§€ëŠ” ì•Šì€ì§€ íŒŒì•…í•©ë‹ˆë‹¤. ë˜í•œ, ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ëˆˆìœ¼ë¡œ íŒŒì•…í•˜ëŠ” ê²ƒì´ ì§ê´€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¤ëª…ë³€ìˆ˜ì™€ ì‘ë‹µë³€ìˆ˜ ê°„, í˜¹ì€ ì„¤ëª…ë³€ìˆ˜ ê°„ì˜ ì‚°ì ë„ë¥¼ ê·¸ë ¤ ì„ í˜•/ë¹„ì„ í˜• ê´€ê³„ë¥¼ íŒŒì•…í•˜ê±°ë‚˜, ë°ì´í„° ì´í•´ì— ë„ì›€ì´ ë˜ëŠ” ì‹œê°í™”ë¥¼ í•´ë´…ë‹ˆë‹¤.

ğŸ“š reference : 1ì£¼ì°¨ / 5ì£¼ì°¨ ë°ì´í„° ë¶„ì„ ì˜ˆì‹œ ë…¸íŠ¸ë¶, ê³µëª¨ì „ ë¦¬ë”ë³´ë“œ, ESC ì˜ˆì „ íŒŒì´ë„ í”„ë¡œì íŠ¸ repo ë“±ë“±!



ğŸ‘©ğŸ»â€ğŸ’» **ì¤‘ê°„ì ê²€ (Week 10 : May 27th)** : ë‹¤ìŒ ì£¼ ì„¸ì…˜ì—ì„œ ì´ë²ˆí•™ê¸° ìƒˆë¡œ ë¶€ì„í•˜ì‹  ì •ì„±í˜„ êµìˆ˜ë‹˜ì´ 30ë¶„ ì •ë„ ì§§ê²Œ íŠ¹ê°•ì„ í•´ ì£¼ì‹¤ ì˜ˆì •ì…ë‹ˆë‹¤! êµìˆ˜ë‹˜ íŠ¹ê°• í›„ì— ì¡°ë³„ë¡œ ëŒì•„ê°€ë©´ì„œ 10ë¶„ ë‚´ì™¸ë¡œ ê°„ë‹¨í•˜ê²Œ ì†Œê°œí•œ ë°ì´í„° ì„¤ëª…, 1ì£¼ì°¨ ìˆ˜í–‰ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ ë°œí‘œí•´ì£¼ì‹œê³ , ì–´ë ¤ìš´ ì ì´ë‚˜ ê¶ê¸ˆí•œ ì ì„ ê³µìœ í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.



**2ì£¼ì°¨ : Modeling / Model Selection / Interpretation**

Bayesian Linear Regression ë°©ë²•ì„ ì‚¬ìš©í•´ ì „ ì£¼ì— ì¤€ë¹„í•œ ì„¤ëª…ë³€ìˆ˜ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤.

- **Modeling** : Frequentist ê´€ì ì—ì„œ ì¼ë°˜ì ì¸ íšŒê·€ ëª¨í˜•ì„ ìš°ì„  ì í•©ì‹œì¼œ ë³´ê³ , Bayesian Linear Regressionì„ í†µí•´ì„œë„ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ë‘ ë°©ë²•ë¡  ê°„ì— ì–´ë–¤ ì°¨ì´ê°€ ìˆì„ê¹Œìš”?

- **Model Selection** : ëª¨ë¸ ì„¤ë ‰ì…˜ì˜ ì˜ë¯¸ëŠ” í¬ê²Œ 2 ê°€ì§€ì…ë‹ˆë‹¤. ëª¨ë¸ì˜ CV ì—ëŸ¬(Bias - Variance Tradeoff), ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ ì—¬ë¶€ ë“±ì„ ê³ ë ¤í•©ë‹ˆë‹¤.

  1. ëª¨ë¸ ìì²´ì˜ ì„ íƒ: ì˜ˆì»¨ëŒ€ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì“¸ì§€, SVMì„ ì“¸ì§€, Random Forestë¥¼ ì“¸ì§€, í˜¹ì€ ì´ ëª¨ë‘ë¥¼ í•¨ê»˜ ì“°ëŠ” Voting Classifierë¥¼ ì“¸ì§€ ê²°ì •í•©ë‹ˆë‹¤.
  2. ëª¨ë¸ ë‚´ ë³€ìˆ˜ì˜ ì„ íƒ: ì–´ë–¤ ë³€ìˆ˜ë¥¼ ì“¸ì§€, ì–´ë–¤ ì ì¬ë³€ìˆ˜ë¥¼ ê³ ë ¤í• ì§€ ë“±ì„ ê²°ì •í•©ë‹ˆë‹¤. (ì´ë²ˆ ì£¼ì— ë°°ìš´ ë‚´ìš©!)

  ê·¸ë ‡ì§€ë§Œ ì´ë²ˆ í”„ë¡œì íŠ¸ì˜ ê²½ìš° í¬ê²Œ linear regression í•œ ê°€ì§€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— 2ë²ˆ ëª¨ë¸ ë‚´ ë³€ìˆ˜ì˜ ì„ íƒì— í•´ë‹¹í•©ë‹ˆë‹¤.

  ë¹ˆë„ë¡ ì  ê´€ì ì—ì„œ íšŒê·€ë¶„ì„ì„ ì‹¤ì‹œí•˜ì˜€ë‹¤ë©´ forward / backward selection, information criterion ë“±ì„ ì‚¬ìš©í•˜ì—¬ model selectionì„ í•  ìˆ˜ ìˆê² ê³ , ì´ë²ˆ ì£¼ì— ë°°ìš´ ë‚´ìš©ì„ í† ëŒ€ë¡œ Bayesian model selectionì„ í†µí•´ì„œë„ feature selectionì„ í•˜ì—¬ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”. ë‘ ê´€ì  ëª¨ë‘ì—ì„œ ì ìš© ë° í•´ì„ì´ ê°€ëŠ¥í•œ Lasso / Ridge ë“±ì˜ penalizing methodë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

- **Interpretation** : Evaluationì´ ì£¼ëœ ëª©ì ì€ ì•„ë‹ˆì§€ë§Œ ë¶„ì„ ê³¼ì œì— ë§ê²Œ metricì„ ì •í•˜ê³  ê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤. ê³µëª¨ì „ ë°ì´í„°ì²˜ëŸ¼ metricì´ë‚˜ í‰ê°€ì— ì‚¬ìš©í•˜ëŠ” scoreê°€ ì •í•´ì ¸ ìˆëŠ” ê²½ìš°ë„ ìˆê³ , ë‹¨ìˆœ MSEë¥¼ ì‚¬ìš©í•  ìˆ˜ë„, binary classificationì´ë¼ë©´ contingency tableì„ ë³´ëŠ” ë°©ë²• ë“±ì´ ìˆìŠµë‹ˆë‹¤. ì˜ ì˜ˆì¸¡í•˜ëŠ” ê²ƒë„ ì¤‘ìš”í•˜ì§€ë§Œ ê·¸ì— ëª»ì§€ì•Šê²Œ ëª¨ë¸ì„ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ê²ƒë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì–´ë–¤ ë³€ìˆ˜ê°€ ì¤‘ìš”í•œì§€ (ë‚˜ì•„ê°€ ì™œ ì¤‘ìš”í•œì§€ ë‚˜ë¦„ì˜ í•´ì„ì´ ìˆìœ¼ë©´ ì¢‹ê² ì£ ?), íšŒê·€ ê³„ìˆ˜ë‚˜ feature selectionì˜ Importance ê°’ì„ ê·¼ê±°ë¡œ ì œì‹œí•˜ê³  ê·¸ ì´ìœ ë¥¼ ìƒê°í•´ë³´ë©´ ë©ë‹ˆë‹¤.

  

ğŸ‘©ğŸ»â€ğŸ’» **ìµœì¢… ë°œí‘œ (Week 11 : June 3rd)** : 2ì£¼ ê°„ íŒŒì´ë„ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•œ ë‚´ìš©ì„ íŒ€ë³„ë¡œ 15ë¶„ ì´ë‚´ë¡œ ë°œí‘œí•´ì£¼ì„¸ìš”. ë‰´ëŸ´ë„·ì´ë‚˜ ë¶€ìŠ¤íŒ… ë“±ì˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— score ìì²´ëŠ” ì¢‹ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” ê²°ê³¼ê°€ ì¢‹ì§€ ì•Šë”ë¼ë„ ì™œ ì¢‹ì§€ ì•Šì•˜ì„ì§€ ìƒê°í•´ë³¸ ë‚´ìš©ì´ë‚˜ improvement ë“±ì„ ê³ ë¯¼í•´ë³´ì‹œê³  ë°œí‘œí•´ì£¼ì„¸ìš”. í•œ í•™ê¸°ë™ì•ˆ ë°°ìš´ ë‚´ìš©ê³¼ ì—°ê´€ì§€ì–´ ê²°ê³¼ë¥¼ ì˜ í•´ì„í•˜ê³  ëª¨ë¸ê³¼ ë³€ìˆ˜ë¥¼ ì˜ ì„¤ëª…í•˜ëŠ” ê²Œ ì¤‘ìš”í•©ë‹ˆë‹¤!



### 3. Datasets

\* ì•„ë˜ì— ì œì‹œëœ ë°ì´í„°ì…‹ ì™¸ì— ë‹¤ë¥¸ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì…”ë„ ë¬´ë°©í•©ë‹ˆë‹¤!

#### Regression Problem

- **[DACON] ì•„íŒŒíŠ¸ ê²½ë§¤ê°€ê²© ì˜ˆì¸¡**

  - ì•„íŒŒíŠ¸ ë‚™ì°°ê°€ ì˜ˆì¸¡í•˜ê¸°

    í•œêµ­ì˜ ì„œìš¸ê³¼ ë¶€ì‚° ì§€ì—­ ì•½ 2,700ì—¬ê°œ ìµœê·¼ 2ë…„ê°„ ì•„íŒŒíŠ¸ ê²½ë§¤ë¬¼ì˜ ë“±ê¸°ë¶€, ì„ì°¨, ê°ì •ê°€, ìœ ì°° íšŸìˆ˜, ë‚™ì°°ê°€ ë“±ì˜ ì •ë³´ê°€ ì œê³µë©ë‹ˆë‹¤. 

  - original link : https://dacon.io/competitions/official/17801/data

    (ë¹„ìŠ·í•œ ë°ì´í„°ë¡œ kaggleì˜ house price ì˜ˆì¸¡ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤ : https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)

  - evaluation metric : RMSE (Root Mean Squared Error)

  - ìì„¸í•œ descriptionì€ dacon í™ˆí˜ì´ì§€ë¥¼ ì°¸ì¡°

  - íŠ¹ì´ì‚¬í•­ : test setì˜ ì •ë‹µì´ ë”°ë¡œ ì œê³µë˜ì§€ ì•ŠëŠ”ë“¯í•˜ë¯€ë¡œ train testì—ì„œ ì ë‹¹íˆ split í•„ìš”



- **[UCI / ESC] ë²”ì£„ì§€ë„ ë§Œë“¤ê¸°**

  - ë² ì´ì§€ì•ˆ methodë¥¼ ì´ìš©í•˜ì—¬ ë²”ì£„ì§€ë„ ì™„ì„±í•˜ê¸°
  - 2215 obs. of 147 variables
  - 8ì¢… ë²”ì£„ : murders / rapes / robberies / assaults / burglaries / larcenies / autoTheft / arsons
  - original src : http://archive.ics.uci.edu/ml/datasets/communities+and+crime (dimension ì•½ê°„ ë‹¤ë¦„)
  - ê²°ì¸¡ì¹˜ O
  - recommended materials : https://statkclee.github.io/spatial/
  - íŠ¹ì´ì‚¬í•­ : mapping & rigorous visualization, many multiple response variables

  

- **[ASA Datafest / Microsoft Build] Predicting Airline Delay**

  - ë¹„í–‰ê¸° ë„ì°©ì§€ì—°ì‹œê°„ ì˜ˆì¸¡í•˜ê¸° (arr_delay)

  - Airline on-time performance data for the years 1987 through 2008 was used in the American Statistical Association Data Expo in 2009 (http://stat-computing.org/dataexpo/2009/). ASA describes the data set as follows:

    > The data consists of flight arrival and departure details for all commercial flights within the USA, from October 1987 to April 2008. This is a large dataset: there are nearly 120 million records in total, and takes up 1.6 gigabytes of space compressed and 12 gigabytes when uncompressed.

    ì›”ë³„ ë°ì´í„°ëŠ” ë”°ë¡œ ë°›ì„ ìˆ˜ ìˆê³ , `AirOnTime87to12.xdf` ê°€ ì „ì²´ data (ì••ì¶• í•´ì œ ì‹œ 12GB...), ì „ì²´ data ì¤‘ 7% ì •ë„ë§Œ ì¶”ì¶œí•œ ê²ƒì´ `AirOnTime7Pct.xdf`ì´ë‹¤.

    Row ìˆ˜ê°€ êµ‰ì¥íˆ ë§ê¸° ë•Œë¬¸ì— 2012ë…„ë„ì˜ data ë˜ëŠ” íŠ¹ì • ì—°ë„ì˜ dataë¥¼ ê³¨ë¼ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥ 

    2012 : https://packages.revolutionanalytics.com/datasets/AirOnTimeCSV2012/

    1987-2008 database : https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2FHG7NV7&version=&q=&fileTypeGroupFacet=&fileAccess=&fileSortField=name&fileSortOrder=desc

    2015 : https://www.kaggle.com/usdot/flight-delays/code?datasetId=810&sortBy=voteCount

  - íŠ¹ì´ì‚¬í•­ : large data, ì‹œê³„ì—´ ë³€ìˆ˜ O, ê²°ì¸¡ì¹˜ O, ë²”ì£¼í˜• ë³€ìˆ˜

    (ì›ë˜ëŠ” Microsoft Buildì—ì„œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ë¶„ì„í•˜ëŠ” ì˜ˆì‹œì—ì„œ ì‚¬ìš©ë¨. í˜¹ì‹œë¼ë„ 150million recordê°€ ì „ë¶€ í¬í•¨ëœ .xdf íŒŒì¼ì„ ì‚¬ìš©í•´ë³´ê³  ì‹¶ì€ íŒ€ì€ https://docs.microsoft.com/en-us/machine-learning-server/r/tutorial-revoscaler-large-data-airline#download-the-airline-dataset ì°¸ì¡°. Microsoft / linux í™˜ê²½ì—ì„œë§Œ ê°€ëŠ¥)

  

#### Classification Problem (Binary Response - Logistic Regression / GLM)

\* Logistic problemì„ ì„ íƒí•˜ì‹  ë¶„ë“¤ì€ ê°„ì‚¬ë‹˜ê»˜ì„œ ë”°ë¡œ ëª¨ë¸ë§ì— ë“¤ì–´ê°€ê¸° ì „ì— ì¡°ê¸ˆ ë” ì‹¬í™”ëœ ë°©ë²•ë¡ ì´ë‘ ì½”ë“œë¥¼ ì„¤ëª…í•´ ì£¼ì‹¤ ì˜ˆì •ì…ë‹ˆë‹¤! (ì¤‘ê°„ë°œí‘œ ì „ë‚  ì •ë„?)

- **[COMPAS] ê¹€í•´ì‹œ í™”ì¬ë°œìƒ ì˜ˆì¸¡ëª¨ë¸**
  
  - ê²½ë‚¨ì§€ì—­ ë°ì´í„°ë¥¼ ì´ìš©í•´, ê¹€í•´ì‹œì˜ í™”ì¬ ë°œìƒì„ ì˜ˆì¸¡í•˜ê¸°
  
  - 63 columns / fr_yn ì˜ˆì¸¡ (binary response)
  - train (ê²½ë‚¨ì§€ì—­) / validation (ê¹€í•´ì§€ì—­) set
  - ê²°ì¸¡ì¹˜ ì—¬ë¶€ O / ì‹œê³„ì—´ ë³€ìˆ˜ O
  - original link : https://compas.lh.or.kr/subj/past/info?subjNo=SBJ_1910_002
  - ìì„¸í•œ descriptionì€ compas í™ˆí˜ì´ì§€ë¥¼ ì°¸ì¡°



- **[KAGGLE] ALL-NBA awards ìˆ˜ìƒ ì˜ˆì¸¡**

  - ALL-NBA ìˆ˜ìƒ ì˜ˆì¸¡ (binary response)

  - description : kaggleì˜ 1950ë…„ë„ë¶€í„° NBA ì„ ìˆ˜ë“¤ì˜ ì‹œì¦Œ ìŠ¤íƒ¯ ë°ì´í„°ì— ì œê°€ ë‹¹í•´ ALL-NBA ìˆ˜ìƒ ì—¬ë¶€ë¥¼ binary variableë¡œ ë¶™ì¸ ë°ì´í„°ì…ë‹ˆë‹¤.

    The All-NBA Team is an annual NBA awards given to the best players in the league every following season, whose vote is conducted by a panel of sportswriters and broadcasters. The award dates back to 1946, however, since 1988 the ALL-NBA team is composed of three teams of 5 players. Being included in the team is a great honor for players and it affects playersâ€™ reputation and value.

    Dataset : Players and season stats data from Kaggle contains aggregate individual statistics for 67 NBA seasons from 1950 to 2017. There are 59 columns, data originally scraped from basketball-reference.com. Features include standard statistics (e.g. points, rebounds, turnover, etc.), advanced metrics (e.g. Player Efficiency Rate, Win Share, etc.), and categorical variables (e.g. position, team)

    1989 = 1988-1989 season

    15582 rows

  - train / test setì„ ì–´ë–»ê²Œ ë‚˜ëˆ ì•¼ í• ì§€ ìƒê°í•´ë³´ì„¸ìš”!
  
  - original link : https://www.kaggle.com/drgilermo/nba-players-stats?select=player_data.csv
  
  - ì˜ˆì¸¡ë³€ìˆ˜ë¥¼ salaryë¡œ ë°”ê¾¸ë©´ classification problemì´ ì•„ë‹ˆë¼ regression problemìœ¼ë¡œ í’€ ìˆ˜ ìˆìŠµë‹ˆë‹¤!
  
    https://www.kaggle.com/whitefero/nba-player-salary-19902017
  
    (\* ë‹¤ë§Œ ì´ë ‡ê²Œ í•˜ë ¤ë©´ data integrationì„ í•´ì„œ í•©ì³ì§„ ë‘ ë°ì´í„°ê°€ ì“¸ ë§Œ í•œì§€ ì‚¬ì „ì— ì²´í¬í•´ ë³´ì…”ì•¼ í•©ë‹ˆë‹¤!)
    
  - íŠ¹ì´ì‚¬í•­ : ê²°ì¸¡ì¹˜ O, class imbalance, categorical variables, ë†êµ¬ì— ëŒ€í•œ í•´ë°•í•œ ì§€ì‹ í•„ìš”..



- **BCG customer churn ì˜ˆì¸¡**
  - BCG case competition data
  - ì—¬ëŸ¬ë¶„ë“¤ì´ Boston Consulting Groupì˜ consultantë¼ê³  ìƒê°í•˜ê³  ê³ ê°ì¸ ì—ë„ˆì§€ íšŒì‚¬ PowerCoì˜ ê³ ê° ì´íƒˆ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ê³  ì–´ë–»ê²Œ í•˜ë©´ ì´íƒˆì„ ë§‰ì„ ìˆ˜ ìˆì„ì§€ ë°©ì•ˆ ì œì‹œí•˜ê¸°
  - binary response
  - case description / code book ì œê³µ



### 4. Reference

**[demo]**

\- R : https://github.com/avehtari/modelselection

\- python : https://www.quantstart.com/articles/Bayesian-Linear-Regression-Models-with-PyMC3/

**[article]**

\- https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7

ê·¸ ì™¸ êµ¬ê¸€ë§, ë˜ êµ¬ê¸€ë§...